# docker-loadtesting
Load testing results per our docker sprint

Автор исследования: LintixerDA, а также некоторые мысли expeexpeexpe (Александра)

Описание тестовых стендов
Тестирование проводилось на трёх виртуальных машинах в облаке, каждая из которых имела следующие характеристики:
•	операционная система: Linux (Ubuntu 24.04.1 LTS, ядро 6.8.0-47-generic);
•	оперативная память: 64 ГБ (из них до 1 ГБ занят другими процессами);
•	процессор: Intel Xeon Platinum 8358 @ 2.60GHz (32 ядра, 1 поток на ядро (хотя должно быть 2, магия));
•	сетевое подключение: минимум 1 Гбит Ethernet (не проверялось);
•	дисковая подсистема: не проверялась.

На основной машине был развёрнут Nginx в трёх различных конфигурациях:
1.	nginx на хостовой машине с использованием нестандартного порта (6969);
2.	nginx в Docker-контейнере с использованием сетевой подсистемы хоста;
3.	nginx в Docker-контейнере с проксированием запросов с 80 порта на 8080.

Запросы отправлялись с двух тестирующих машин (далее — "tester").
Конфигурация веб-серверов никак не менялась (кроме портов), то есть тестирование проводилось с базовыми страницами nginx, что крайне усложняло возможность нагрузить целевой сервер по максимуму, так как никаких страниц авторизации, корзин, скачиваний и т.п. не было.

Методика тестирования
Исследование было направлено на изучение пределов нагрузки веб-сервера с учётом использования CPU и оперативной памяти. Методика заключалась в отправке больших объёмов HTTP-запросов на каждый Web-сервер по отдельности с двух тестеров одновременно. Основные метрики включали:
•	общее количество отправленных запросов;
•	количество успешных запросов (код 200);
•	общее время обработки запросов;
•	потребление ресурсов (CPU, RAM) на основной и тестирующих машинах.

Для тестирования использовались утилиты hey и wrk.

Теоретические основы
Любая дополнительная логика или прослойка в системах контейнеризации вносит определённый оверхед. Например, при больших объёмах трафика каждая строка правил фаервола может добавлять задержку в обработку запроса. Это также относится и к Docker: хотя теоретически контейнеризация неизбежно создаёт некоторый оверхед, на практике, в конфигурации с использованием сетевой подсистемы хоста (--net=host), разница с Nginx на хосте минимальна. Это связано с отсутствием дополнительных маршрутов или сложных цепочек правил фаервола. Однако при использовании docker-proxy для проксирования запросов через другие порты (например, с 80 на 8080), потери производительности могут достигать десятков процентов из-за дополнительной прослойки.

Практические результаты
Тесты показали, что результаты сильно зависят не только от конфигурации сервера, но и от методики тестирования, особенностей выбранных инструментов и мощности тестовых машин. А теперь по порядку.
Было использовано множество различных вариантов команд с hey или wrk. Главная проблема заключалась в том, что или tester были перегружены, что давало уменьшение нагрузки на целевой сервер, или недостаточно нагружены, что также влияло на уменьшение нагрузки. Методом тыка было обнаружено 2 команды, которые нагружают tester по лимиту, но не перегружают его:
•	hey -n 2400000 -c 40000 -H "User-Agent: CustomAgent" http://ip/index.html 
•	wrk -t32 -c40000 -d1m -H "User-Agent: CustomAgent" http://ip/index.html

Также на tester были прописаны следующие параметры:
•	ulimit -n 65535 для увеличения лимита файловых дескрипторов;
•	в файле sysctl.conf:
1.	net.core.somaxconn = 65535;
2.	net.ipv4.ip_local_port_range = 1024 65535;
3.	net.ipv4.tcp_fin_timeout = 15.

Таким образом, были изменены параметры ОС. Также в результатах будет участвовать только утилита wrk. Во время данной работы было обнаружно, что hey значительно слабее нагружает сервер по сравнению с wrk, хотя нагрузка на тестеры оставалась одинаковой. Стоит еще учесть тот момент, что обе эти утилиты крайне неравномерно нагружают все ядра процессора. И еще у них ограниченный функционал по сравнению с другими, например, JMeter или K6. Таким образом, выбор этих утилит был не самым удачным. Ниже находится скрин нагрузки на CPU на tester через мониторинг. Смотреть преимущественно стоит только с промежутка 23:20 до 23:50. Как видно, нагрузка не достигла даже 50%. При попытке увеличить нагрузку, tester начинал работать нестабильно.
![image](https://github.com/user-attachments/assets/a1a3d9f8-b739-4679-96d9-c92332a8ae38)

При этом во всех тестах нагрузка на CPU на целевом сервере была до 2100%, но это не мешало спокойно работать веб-серверу. Также по графику, который ниже, CPU был нагружен по итогу всего на 40%. Результаты лучше также смотреть с 23:20 по 23:50.
![image](https://github.com/user-attachments/assets/fc24b67e-a27c-46ed-9843-617439eb2ae7)

Можно еще сразу уточнить, что ОЗУ была съедена до 220Мб, но есть еще одно, но… Чем дольше шли запросы на целевой сервер, тем больше потреблялось памяти, и по логике, при достаточном количестве времени можно выйти за пределы. 
Результаты тестирования
wrk -t32 -c40000 -d1m -H "User-Agent: CustomAgent" http://ip/index.html
1.	Nginx на хосте (порт 6969)
![image](https://github.com/user-attachments/assets/a09a5aed-1ac5-4840-91b5-8892d54ee891)
![image](https://github.com/user-attachments/assets/ce7c1e4b-35db-45aa-ad8f-0c8567bea4a2)
![image](https://github.com/user-attachments/assets/f48a983c-c776-4c09-a677-6dbda28da05f)

2.	Nginx в Docker с проксированием (порт 8080)
![image](https://github.com/user-attachments/assets/05ac7500-6ff7-4b5e-8bb6-3d6ca14d8065)
![image](https://github.com/user-attachments/assets/4664c6bd-f3cf-4c51-ae9a-e8888939ab3d)
![image](https://github.com/user-attachments/assets/cac94716-0023-4771-bcd2-d6d3da2fe465)

3.	Nginx в Docker с использованием сетевой подсистемы хоста
![image](https://github.com/user-attachments/assets/fa9eac09-3e87-407a-b270-d8d9672df807)
![image](https://github.com/user-attachments/assets/64e215e9-f86f-4227-bba2-74f5fe5a7088)
![image](https://github.com/user-attachments/assets/f6edad3f-c85f-4e93-b72f-09d746b5cc4d)

Также представлен график успешных и неуспешных запросов:
![image](https://github.com/user-attachments/assets/b9c0c4b8-ce6e-44ff-90c6-6df8087d9f96)

Как видно, в двух из трех тестов Tester 1 по какой-то причине не захотел адекватно отправлять запросы. В рамках ограниченного времени не удалось это заметить сразу, поэтому отбросим первый тестер и будем сравнивать только по второму. В данном случае, это допустимо, так как целевой сервер не испытывал никаких проблем при нагрузках. Новый график изображен ниже:
![image](https://github.com/user-attachments/assets/d94006bd-c0e5-4538-959f-000d633263db)

1.	Nginx на хосте (порт 6969):
o	Обработано около 2.4 млн запросов.
o	Уровень ошибок: ~10%.
2.	Nginx в Docker с проксированием (порт 8080):
o	Обработано более 4 млн запросов.
o	Уровень ошибок: ~5%.
3.	Nginx в Docker с сетевой подсистемой хоста:
o	Обработано более 4 млн запросов.
o	Уровень ошибок: ~2%.
![image](https://github.com/user-attachments/assets/b1510c08-e006-4747-8fb8-8c19f2bff47a)

Этот график иллюстрирует, что конфигурация с сетевой подсистемой хоста обеспечивает лучший баланс между количеством запросов и минимальным количеством ошибок, тогда как использование Docker-прокси добавляет значительные потери производительности. 

Дополнительные наблюдения
•	Контейнеризация: несмотря на теоретические потери от Docker, конфигурация с использованием сетевой подсистемы хоста продемонстрировала минимальные задержки и совсем не уступала по производительности Nginx на хосте.
•	Docker-proxy: конфигурация с проксированием запросов показала худшие результаты, с большим количеством ошибок и заметным снижением производительности.

Выводы
Контейнер с сетевой подсистемой хоста продемонстрировал наилучший баланс между количеством обработанных запросов, стабильностью и минимальной задержкой. Контейнер с проксированием (docker-proxy) показал значительно большие потери производительности и количество ошибок, что указывает на его меньшую эффективность при высоких нагрузках. Nginx на хосте был наиболее уязвим к ошибкам и показал самую низкую производительность, несмотря на отсутствие контейнерных прослоек, что достаточно странно.
Тест выявил множество факторов, которые нужно учитывать в нагруженных системах, начиная от тюнинга тестеров до конфигурации веб-сервера.
